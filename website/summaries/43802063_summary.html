<section>
    <nav><ul><li><a href="..">Articles</a></li></ul></nav>
    <article>
        <h1>Mike Lindell&#39;s lawyers used AI to write briefâ€“judge finds nearly 30 mistakes</h1>
        <p>
<div>
  <h3>Summary</h3>
  <p>
    According to an Ars Technica article published in April 2025, lawyers representing MyPillow CEO Mike Lindell in a defamation lawsuit before the Eighth Circuit Court of Appeals appear to have used artificial intelligence to draft a legal brief. The brief contained citations to nonexistent cases. Judge Ralph Erickson brought this issue to light, noting that several cases cited in the brief could not be found in legal databases like Westlaw or LexisNexis and seemed to be entirely fabricated.
  </p>
  <p>
    The questionable cases cited in the brief include names like <i>Vadim v. Garmin</i>, <i>Crabill v. Transunion</i>, and <i>United States ex rel. Sanders v. Allison Engine Co.</i> According to Erickson, a basic search reveals no record of these cases ever existing. Erickson has ordered Lindell's legal team to explain how these fictional cases ended up in their brief. This incident raises serious questions about the use of AI in legal research and writing, especially regarding the technology's potential to fabricate information.
  </p>
  <p>
    The issue underscores the challenges of relying on AI tools without careful verification of the output. If the lawyers did indeed use AI to generate parts of their brief without proper oversight, it could have severe repercussions, including potential sanctions. The legal community is now grappling with the ethical and practical implications of AI in legal practice, emphasizing the need for thorough fact-checking and human oversight when utilizing these technologies.
  </p>
  <p>
    The case highlights concerns about the reliability of AI-generated content and the importance of human verification in legal contexts, where accuracy and integrity are paramount. The incident serves as a cautionary tale for legal professionals considering integrating AI tools into their workflows, suggesting that while AI can assist with research and writing, it should not replace the critical thinking and fact-checking skills of experienced lawyers.
  </p>

  <h3>Key Points</h3>
  <ul>
    <li>MyPillow CEO Mike Lindell's lawyers submitted a legal brief to the Eighth Circuit Court of Appeals that cited nonexistent cases.</li>
    <li>Judge Ralph Erickson discovered the fabricated case citations, including cases such as <i>Vadim v. Garmin</i>, <i>Crabill v. Transunion</i>, and <i>United States ex rel. Sanders v. Allison Engine Co.</i></li>
    <li>The judge suspects that the lawyers may have used AI to generate parts of the brief, resulting in the inclusion of fictional cases.</li>
    <li>Erickson has ordered Lindell's legal team to explain how these fake cases were cited in their brief.</li>
    <li>The incident raises concerns about the reliability of AI in legal research and writing and the necessity of human verification.</li>
    <li>The case may lead to sanctions for the lawyers if they are found to have relied on AI-generated content without proper oversight.</li>
    <li>The incident highlights the ethical and practical challenges of using AI in the legal profession.</li>
    <li>The article underscores the need for caution and thorough fact-checking when utilizing AI tools in legal contexts.</li>
  </ul>
</div>
</p>
    </article>
</section>
