<article>
    <h2>Anthropic tightens usage limits for Claude Code without telling users</h2>
    <div>
<div>
<p>Anthropic, an AI company, has reportedly tightened usage limits for its Claude AI model's code generation capabilities without informing its users. Several developers have noticed a significant reduction in the amount of code Claude can generate in a single response, with the model often cutting off code blocks prematurely. This change appears to have been implemented silently, as Anthropic did not announce any updates to Claude's limitations.</p>

<p>Developers are expressing frustration over this unannounced restriction, as it disrupts their workflows and requires them to make multiple requests to get the complete code. They are also concerned about the lack of transparency from Anthropic, as they were not given any prior notice about the change. Some speculate that the reduction in code generation capabilities may be due to cost-saving measures or efforts to prevent abuse of the model, but without official communication from Anthropic, the exact reason remains unclear.</p>

<p>The article highlights the importance of clear communication and transparency from AI companies regarding changes to their models' capabilities. Unannounced changes can negatively impact developers' productivity and trust in the platform.</p>

<h2>Key Points:</h2>
<ul>
<li>Anthropic has reportedly reduced the amount of code Claude can generate in a single response.</li>
<li>This change was implemented without any prior announcement or communication to users.</li>
<li>Developers are frustrated by the reduced code generation capabilities and lack of transparency.</li>
<li>The reason for the change is unknown, but potential explanations include cost-saving measures or abuse prevention.</li>
<li>The incident highlights the importance of clear communication from AI companies regarding changes to their models.</li>
</ul>
</div>
</div>
</article>
