<article>
    <h2>Voxtral-Mini-3B-2507 â€“ Open source speech understanding model</h2>
    <div>
<div>
<h2>Summary</h2>
The article describes Voxtral-Mini-3B-2507, a small yet capable language model developed by Mistral AI. It is a 3 billion parameter model fine-tuned from Mistral-7B-v0.1 specifically for speech-related tasks. This model demonstrates strong performance in multilingual automatic speech recognition (ASR) and speech translation, supporting a wide range of languages. The model is particularly notable for its efficient size, which enables it to be deployed on devices with limited computational resources, opening up possibilities for on-device speech processing applications. The model weights are publicly available, which promotes further research and development in the field of speech technology.
<br/>
<h2>Key Points</h2>
<ul>
<li><b>Model Name:</b> Voxtral-Mini-3B-2507</li>
<li><b>Developer:</b> Mistral AI</li>
<li><b>Size:</b> 3 billion parameters</li>
<li><b>Base Model:</b> Fine-tuned from Mistral-7B-v0.1</li>
<li><b>Primary Task:</b> Speech-related tasks, including Automatic Speech Recognition (ASR) and Speech Translation</li>
<li><b>Multilingual Support:</b> Supports a variety of languages for ASR and speech translation.</li>
<li><b>Efficiency:</b> Designed to be efficient and deployable on devices with limited resources.</li>
<li><b>Availability:</b> Model weights are publicly available.</li>
</ul>
</div>
</div>
</article>
